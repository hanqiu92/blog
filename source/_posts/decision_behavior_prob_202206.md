---
title: 'Decision Behavior Note I: Probability Judgement'
categories: Study Notes
tags:
- Behavior Modeling
- Reinforcement Learning
mathjax: true
date: 2022-06-04 00:00:00
---

<!-- motivation -->

最近，我对一系列经典的研究人类决策行为的书籍进行了学习，并尝试从决策学习算法设计的角度进行分析解释。在下面这一系列文章中，希望通过对上述这些学习和分析进行整理，我们能够一方面更好地认识到人们决策行为中的局限性和相应的校正方法，另一方面为自动化决策算法的设计和优化提供新的思路。

在这份笔记中，我将先对[Judgement under Uncertainty: Heuristics and Biases](https://www.amazon.com/Judgment-Under-Uncertainty-Heuristics-Biases/dp/0521284147)这本关注概率判断的书中的主要结论进行整理。

<!--more-->

## 证据 Evidences

首先，在这一节中，我将对书中描述的数种决策偏差现象进行归纳整理。

1. 代表性：人们倾向于关注那些更能代表**总体分布**或**样本生成流程**的证据和样本上，并使用这种关注度的强弱作为概率判断的基础。
   * 证据（条件）信息 > 基率（先验）信息：人们在进行推理和归因时，倾向于过度关注证据/个体的信息，而忽略基率/共识性的信息。
   * 证据内容 > 证据质量：人们在利用同样的证据对不同的预测周期的任务进行推理时，结果无显著差异，说明推理结果不会随证据可信度下降而回归到先验概率上。
   * 原因基率 > 偶然基率：与结论有更强因果关联的先验信息更容易被人们纳入推理过程中。
   * 原因推理（从因到果） > 诊断推理（从果到因）：对于随机性的结果，人们倾向于挖掘新的解释原因（过度归因/后知之明），而非诊断现有推理流程的问题（进行模型的回归）。
   * 总体统计量 > 样本规模：
     * 小数定律：人们倾向于认为小样本也需要具备大样本的统计性质，例如错误地认为布朗运动时均值回归的（赌徒谬误）。
     * 表面随机性/局部同质性定律：人们倾向于赋予具有局部同质性的样本/证据更大的关注度和权重，例如认为在随机抽样中“纯随机序列”（每个子序列都是打散的）出现的基率大于其他序列。
     * 多源同质信息 > 单源信息（效度错觉，illusion of validity）：当给出更多来源的证据时，这些信息的一致性和极端性，会提高人们对预测的信心程度，即便从概率论的角度更多的证据反而会削弱事件发生的概率。
2. 便利性：人们更容易联想到那些**与记忆关联紧密**或**反事实仿真难度低**的证据和样本上，并使用这种注意力的强弱作为概率判断的基础。
   * 个人经历 > 他人经历（自我中心偏差）：
     * 刻板印象/虚假共识：人们通过对对抗性证据的选择性记忆和利用，会实现刻板印象和虚假共识的自我证实和强化。
     * 控制错觉（illusion of control）：人们在过度归因的基础上，倾向于进一步将随机事件的结果归因于自身能力。
   * 消除（undo）异常事件 > 引入（do）异常事件：在反事实判断中，人们更倾向于将异常事件恢复为正常事件，而非引入新的异常事件。
   * 少量因果显著性高事件 > 大量因果显著性低事件：人们倾向于低估由缓慢和累积性变化导致的事件的可能性。
   * 正例 > 负例（伪相关）：人们倾向于仅根据正例、甚至是极端取值的正例判断相关性。
3. 锚定效应：对于序列形式的推理，人们在后面阶段的推理结果倾向于锚定在前面阶段的推理结果的一定波动范围内。
   * 过度自信：对于不确定性估计问题，人们给出的主观分布区间往往过窄，锚定在预期值附近的小范围内。而且，估计问题越难，过度自信越严重。
   * 复合概率中，多阶段概率 ≈ 单阶段概率：对于中间阶段的推理预测，人们往往仅专注于最可能事件，而忽略不太可能发生的事件；特别地，对于（概率）连乘积，人们往往会低估其衰减的速度。
   * 对后验概率的修正速度 < 贝叶斯推理：在使用新息对后验概率进行修正的过程中，人们会更为保守，即后验概率会锚定在先验概率的一定范围内；而且，新息的信息量越高，人们的保守性越大，即修正速度越慢。

## 解释 Explanations

在接下来这一节中，我将尝试从学习算法的角度，对前面介绍的偏差现象进行分析和解释。

1. 代表性与模式识别：在人们对信息进行提取和过滤的过程中，有限的计算容量和一定的泛化性需求要求人们更多采用一种相似性/差异性模式识别的处理方式，即找到信息中最典型和具有代表性的部分并加以应用。这种类似于机器学习方法（特别是决策树）的处理方式，会导致人们对于除样本特征外的其他附加信息相对不敏感（例如，数据样本的分布）。
   * 忽视先验信息：因为人们对训练数据集中的样本分布不敏感（虽然该信息会通过样本权重隐性地被考虑到），因此一旦出现数据集的偏移（dataset shift），已有的输入特征与输出结果之间的映射将无法有效地考虑新任务的先验信息。
   * 忽视样本规模：同样因为模式识别的信息处理机制，人们往往会忽略样本规模的影响，而专注于样本本身所需具备的特征。
   * 忽视样本质量：为简化计算和提高泛化性，人们往往对（看起来）相似的任务共享一组特征提取和映射方法，即使同一组特征对于这些任务来说推理质量有一定差异。
   * 过度重视原因推理：这可能是由于在人们历史的成功学习经验中，基于原因推理的做法比基于诊断推理的做法更典型，进而导致对原因推理这种模式的过度依赖。具体为何原因推理会更加典型，则可以由第3点中的泛化性能来解释。
   * 效度错觉（illusion of validity）：由于人们更善于使用学习的模式、而非信息整合（回归）的模式，因此接收到更多一致的信息时，会倾向于强化现有观念。
2. 便利性与计算复杂度：由于人们对于历史信息的存储容量和检索速度、以及对反事实判断的推理速度是有限的，在信息存储、检索、以及仿真评估等行为中更便于获取的信息将得到更多的关注。
   * 自我中心偏差：人们对自身相关信息的自然偏好，将挤占其他信息的存储空间和检索资源。
   * 反事实判断：人们更偏好消除异常，是因为消除异常动作是二元的，而引入异常动作是连续的，计算复杂度更高。
   * 虚假共识：人们更倾向于处于舒适区中，与自己认可的人与事进行交互，进而导致历史经验中会有更多倾向自身行为的偏差。
   * 坚定信念：人们倾向于从对抗性的证据中，挑选倾向于支持自己信念的证据，即选择偏差（confirmation bias）。
   * 伪相关：客观因素使人们难以收集负例的样本（例如，对于面试的判断准确性问题，人们很难验证“面试判断不通过”候选人的实际表现水平是否也很低），自然会让判断向正例样本倾斜。
3. 锚定效应与泛化性能：在人们的长期学习过程中，由于任务环境往往是非平稳的（每个任务都有自己独特的上下文信息），而且观测样本的信噪比不高（样本与任务之间的关联通常是模糊的），因此学习机制需要较为保守，保证不因为过度激进的迭代而导致泛化性能的下降。
   * 原因推理的优势：因为增加新的解释模型相比采用诊断式的思路来调整模型对原有场景的应用质量会影响更小，泛化性能下降的风险更低，因此人们更偏好采用原因推理。
   * 保守的后验修正速度：在行为研究中，为了能够快速得到结论，实验设计本身存在一定的偏差：任务本身倾向于变得更容易，即观测样本的信噪比高、提供的信息增量大；而因为人们仍然维持一个普适且相对稳定的迭代速率，故相比之下该速率会显得保守。

## 意义 Implications

最终，在这一节中，我们讨论上面这些分析结论能够给我们提供什么指导。

1. 对于人们的决策行为的校正与优化，
   * 首先，决策任务的信息传递方式可以进行更精细的设计，以避免特定类型的偏差。这里，也可以通过利用特定类型的偏差来诱导特定行为（即nudging）。
   * 其次，为提升决策质量，需要引导人们扩大输入信息来源和增加对信息质量的评估，并在决策时综合使用直觉和统计方法进行信息的提取和整合。另外，还可以进一步引入机器规则对人们的决策结果进行校正。
   * 再次，对于长周期的、可重复的任务，可通过引入反馈和训练机制，锻炼人们的决策直觉。
2. 对于自动化决策算法的设计，我们可以更好地预期和理解通用学习流程的局限性，因此有必要根据具体的应用场景进行相应优化。特别地，
   * 由于对经典模式的依赖容易导致代表性偏差，当面对新的任务时，需要适当增加对该任务中各模式特征的先验分布形态和置信程度的评估和利用。换句话说，根据历史经验习得的经典规律，在新场景中是否适用是需要评估验证的。
   * 由于对历史经验的依赖容易导致便利性偏差，当面对新的任务时，可以考虑借助任务属性这类先验信息，动态调整对历史样本的参考权重。另外，在可以收集数据反馈的情况下，可以针对信息密度低的位置加大数据采集频率。换句话说，如果在新任务中有一些历史经验无法应用的地方，可以通过试错法来获取反馈，从而优化长期的决策效果。
